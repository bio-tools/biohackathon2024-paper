@misc{istrate2022largedatasetsoftwarementions,
      title={A large dataset of software mentions in the biomedical literature}, 
      author={Ana-Maria Istrate and Donghui Li and Dario Taraborelli and Michaela Torkar and Boris Veytsman and Ivana Williams},
      year={2022},
      eprint={2209.00693},
      archivePrefix={arXiv},
      primaryClass={cs.DL},
      url={https://arxiv.org/abs/2209.00693}, 
}
@article {PMID35111920,
	Title = {The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central},
	Author = {Schindler, David and Bensmann, Felix and Dietze, Stefan and Krüger, Frank},
	DOI = {10.7717/peerj-cs.835},
	Volume = {8},
	Year = {2022},
	Journal = {PeerJ. Computer science},
	ISSN = {2167-9843},
	Pages = {e835},
	Abstract = {Science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysing data. Thus, transparency about software used as part of the scientific process is crucial to understand provenance of individual research data and insights, is a prerequisite for reproducibility and can enable macro-analysis of the evolution of scientific methods over time. However, missing rigor in software citation practices renders the automated detection and disambiguation of software mentions a challenging problem. In this work, we provide a large-scale analysis of software usage and citation practices facilitated through an unprecedented knowledge graph of software mentions and affiliated metadata generated through supervised information extraction models trained on a unique gold standard &lt;i&gt;corpus&lt;/i&gt; and applied to more than 3 million scientific articles. Our information extraction approach distinguishes different types of software and mentions, disambiguates mentions and outperforms the state-of-the-art significantly, leading to the most comprehensive &lt;i&gt;corpus&lt;/i&gt; of 11.8 M software mentions that are described through a knowledge graph consisting of more than 300 M triples. Our analysis provides insights into the evolution of software usage and citation patterns across various fields, ranks of journals, and impact of publications. Whereas, to the best of our knowledge, this is the most comprehensive analysis of software use and citation at the time, all data and models are shared publicly to facilitate further research into scientific use and citation of software.},
	URL = {https://europepmc.org/articles/PMC8771769},
}
@article {PMID23148064,
	Title = {Comet: an open-source MS/MS sequence database search tool},
	Author = {Eng, Jimmy K and Jahan, Tahmina A and Hoopmann, Michael R},
	DOI = {10.1002/pmic.201200439},
	Number = {1},
	Volume = {13},
	Month = {January},
	Year = {2013},
	Journal = {Proteomics},
	ISSN = {1615-9853},
	Pages = {22—24},
	Abstract = {Proteomics research routinely involves identifying peptides and proteins via MS/MS sequence database search. Thus the database search engine is an integral tool in many proteomics research groups. Here, we introduce the Comet search engine to the existing landscape of commercial and open-source database search tools. Comet is open source, freely available, and based on one of the original sequence database search tools that has been widely used for many years.},
	URL = {https://doi.org/10.1002/pmic.201200439},
}
@article {PMID21622656,
	Title = {CoMet--a web server for comparative functional profiling of metagenomes},
	Author = {Lingner, Thomas and Asshauer, Kathrin Petra and Schreiber, Fabian and Meinicke, Peter},
	DOI = {10.1093/nar/gkr388},
	Number = {Web Server issue},
	Volume = {39},
	Month = {July},
	Year = {2011},
	Journal = {Nucleic acids research},
	ISSN = {0305-1048},
	Pages = {W518—23},
	Abstract = {Analyzing the functional potential of newly sequenced genomes and metagenomes has become a common task in biomedical and biological research. With the advent of high-throughput sequencing technologies comparative metagenomics opens the way to elucidate the genetically determined similarities and differences of complex microbial communities. We developed the web server 'CoMet' (http://comet.gobics.de), which provides an easy-to-use comparative metagenomics platform that is well-suitable for the analysis of large collections of metagenomic short read data. CoMet combines the ORF finding and subsequent assignment of protein sequences to Pfam domain families with a comparative statistical analysis. Besides comprehensive tabular data files, the CoMet server also provides visually interpretable output in terms of hierarchical clustering and multi-dimensional scaling plots and thus allows a quick overview of a given set of metagenomic samples.},
	URL = {https://europepmc.org/articles/PMC3125781},
}
@article {PMID32034124,
	Title = {The COMET toolkit for composing customizable genetic programs in mammalian cells},
	Author = {Donahue, Patrick S and Draut, Joseph W and Muldoon, Joseph J and Edelstein, Hailey I and Bagheri, Neda and Leonard, Joshua N},
	DOI = {10.1038/s41467-019-14147-5},
	Number = {1},
	Volume = {11},
	Month = {February},
	Year = {2020},
	Journal = {Nature communications},
	ISSN = {2041-1723},
	Pages = {779},
	Abstract = {Engineering mammalian cells to carry out sophisticated and customizable genetic programs requires a toolkit of multiple orthogonal and well-characterized transcription factors (TFs). To address this need, we develop the COmposable Mammalian Elements of Transcription (COMET)-an ensemble of TFs and promoters that enable the design and tuning of gene expression to an extent not, to the best of our knowledge, previously possible. COMET currently comprises 44 activating and 12 inhibitory zinc-finger TFs and 83 cognate promoters, combined in a framework that readily accommodates new parts. This system can tune gene expression over three orders of magnitude, provides chemically inducible control of TF activity, and enables single-layer Boolean logic. We also develop a mathematical model that provides mechanistic insights into COMET performance characteristics. Altogether, COMET enables the design and construction of customizable genetic programs in mammalian cells.},
	URL = {https://europepmc.org/articles/PMC7005830},
}
@article {PMID25928765,
	Title = {coMET: visualisation of regional epigenome-wide association scan results and DNA co-methylation patterns},
	Author = {Martin, Tiphaine C and Yet, Idil and Tsai, Pei-Chien and Bell, Jordana T},
	DOI = {10.1186/s12859-015-0568-2},
	Volume = {16},
	Month = {April},
	Year = {2015},
	Journal = {BMC bioinformatics},
	ISSN = {1471-2105},
	Pages = {131},
	Abstract = {&lt;h4&gt;Background&lt;/h4&gt;Epigenome-wide association scans (EWAS) are an increasingly powerful and widely-used approach to assess the role of epigenetic variation in human complex traits. However, this rapidly emerging field lacks dedicated visualisation tools that can display features specific to epigenetic datasets.&lt;h4&gt;Result&lt;/h4&gt;We developed coMET, an R package and online tool for visualisation of EWAS results in a genomic region of interest. coMET generates a regional plot of epigenetic-phenotype association results and the estimated DNA methylation correlation between CpG sites (co-methylation), with further options to visualise genomic annotations based on ENCODE data, gene tracks, reference CpG-sites, and user-defined features. The tool can be used to display phenotype association signals and correlation patterns of microarray or sequencing-based DNA methylation data, such as Illumina Infinium 450k, WGBS, or MeDIP-seq, as well as other types of genomic data, such as gene expression profiles. The software is available as a user-friendly online tool from http://epigen.kcl.ac.uk/comet and as an R Bioconductor package. Source code, examples, and full documentation are also available from GitHub.&lt;h4&gt;Conclusion&lt;/h4&gt;Our new software allows visualisation of EWAS results with functional genomic annotations and with estimation of co-methylation patterns. coMET is available to a wide audience as an online tool and R package, and can be a valuable resource to interpret results in the fast growing field of epigenetics. The software is designed for epigenetic data, but can also be applied to genomic and functional genomic datasets in any species.},
	URL = {https://europepmc.org/articles/PMC4422463},
}
@article {PMID31405382,
	Title = {The bio.tools registry of software tools and data resources for the life sciences},
	Author = {Ison, Jon and Ienasescu, Hans and Chmura, Piotr and Rydza, Emil and Ménager, Hervé and Kalaš, Matúš and Schwämmle, Veit and Grüning, Björn and Beard, Niall and Lopez, Rodrigo and Duvaud, Severine and Stockinger, Heinz and Persson, Bengt and Vařeková, Radka Svobodová and Raček, Tomáš and Vondrášek, Jiří and Peterson, Hedi and Salumets, Ahto and Jonassen, Inge and Hooft, Rob and Nyrönen, Tommi and Valencia, Alfonso and Capella, Salvador and Gelpí, Josep and Zambelli, Federico and Savakis, Babis and Leskošek, Brane and Rapacki, Kristoffer and Blanchet, Christophe and Jimenez, Rafael and Oliveira, Arlindo and Vriend, Gert and Collin, Olivier and van Helden, Jacques and Løngreen, Peter and Brunak, Søren},
	DOI = {10.1186/s13059-019-1772-6},
	Number = {1},
	Volume = {20},
	Month = {August},
	Year = {2019},
	Journal = {Genome biology},
	ISSN = {1474-7596},
	Pages = {164},
	Abstract = {Bioinformaticians and biologists rely increasingly upon workflows for the flexible utilization of the many life science tools that are needed to optimally convert data into knowledge. We outline a pan-European enterprise to provide a catalogue ( https://bio.tools ) of tools and databases that can be used in these workflows. bio.tools not only lists where to find resources, but also provides a wide variety of practical information.},
	URL = {https://europepmc.org/articles/PMC6691543},
}
@article {PMID23479348,
	Title = {EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats},
	Author = {Ison, Jon and Kalas, Matús and Jonassen, Inge and Bolser, Dan and Uludag, Mahmut and McWilliam, Hamish and Malone, James and Lopez, Rodrigo and Pettifer, Steve and Rice, Peter},
	DOI = {10.1093/bioinformatics/btt113},
	Number = {10},
	Volume = {29},
	Month = {May},
	Year = {2013},
	Journal = {Bioinformatics (Oxford, England)},
	ISSN = {1367-4803},
	Pages = {1325—1332},
	Abstract = {&lt;h4&gt;Motivation&lt;/h4&gt;Advancing the search, publication and integration of bioinformatics tools and resources demands consistent machine-understandable descriptions. A comprehensive ontology allowing such descriptions is therefore required.&lt;h4&gt;Results&lt;/h4&gt;EDAM is an ontology of bioinformatics operations (tool or workflow functions), types of data and identifiers, application domains and data formats. EDAM supports semantic annotation of diverse entities such as Web services, databases, programmatic libraries, standalone tools, interactive applications, data schemas, datasets and publications within bioinformatics. EDAM applies to organizing and finding suitable tools and data and to automating their integration into complex applications or workflows. It includes over 2200 defined concepts and has successfully been used for annotations and implementations.&lt;h4&gt;Availability&lt;/h4&gt;The latest stable version of EDAM is available in OWL format from http://edamontology.org/EDAM.owl and in OBO format from http://edamontology.org/EDAM.obo. It can be viewed online at the NCBO BioPortal and the EBI Ontology Lookup Service. For documentation and license please refer to http://edamontology.org. This article describes version 1.2 available at http://edamontology.org/EDAM_1.2.owl.&lt;h4&gt;Contact&lt;/h4&gt;jison@ebi.ac.uk.},
	URL = {https://europepmc.org/articles/PMC3654706},
}
@article {PMID39496564,
	Title = {Optimization of protein identifications through the use of different chromatographic approaches and bioinformatic pipelines},
	Author = {Castaño, Jesus D and Beaudry, Francis},
	DOI = {10.1002/rcm.9937},
	Number = {1},
	Volume = {39},
	Month = {January},
	Year = {2025},
	Journal = {Rapid communications in mass spectrometry : RCM},
	ISSN = {0951-4198},
	Pages = {e9937},
	Abstract = {&lt;h4&gt;Rationale&lt;/h4&gt;Selection of proteomic workflows for a given project can be a daunting task. This research provides a guide outlining the impact on protein identification of different steps such as chromatographic separation, data acquisition strategies, and bioinformatic pipelines. The data presented here will help experts and nonexpert proteomic users to increase proteome coverage and peptide identification.&lt;h4&gt;Methods&lt;/h4&gt;HeLa protein digests were analyzed through different C18 chromatographic columns (15 and 50 cm in length), using top 12 data-dependent acquisition (DDA), top 20 DDA, and data-independent acquisition (DIA) with a nanospray source in positive mode in a Thermo Q Exactive instrument. The raw data were analyzed using different search engines, rescoring approaches, and multi-engine searches. The results were analyzed in the context of peptide and protein identifications, precursor properties, and computation requirements to understand the differences between methods.&lt;h4&gt;Results&lt;/h4&gt;Our results showed that higher column lengths and top N DDA approaches were able to significantly increase protein identifications. The use of multiple search engines yielded limited gains, whereas the use of rescoring methods clearly outperformed other strategies. Finally, DIA approaches, although successful at generating new identifications, had a limited performance influenced by the previous collection of DDA data, which could prohibitively increase instrument time. Nonetheless, the use of library-free methods showed promising results.&lt;h4&gt;Conclusions&lt;/h4&gt;Our results highlight the impact of different experimental approaches on proteome coverage. Changes in chromatographic columns, data acquisition, or bioinformatic analysis can significantly increase the number of protein identifications (&gt;400%). Thus, this research provides a reference upon which to build a successful proteomic workflow with different considerations at every step.},
	URL = {https://doi.org/10.1002/rcm.9937},
}
@article {PMID16729052,
	Title = {A uniform proteomics MS/MS analysis platform utilizing open XML file formats},
	Author = {Keller, Andrew and Eng, Jimmy and Zhang, Ning and Li, Xiao-jun and Aebersold, Ruedi},
	DOI = {10.1038/msb4100024},
	Volume = {1},
	Year = {2005},
	Journal = {Molecular systems biology},
	ISSN = {1744-4292},
	Pages = {2005.0017},
	Abstract = {The analysis of tandem mass (MS/MS) data to identify and quantify proteins is hampered by the heterogeneity of file formats at the raw spectral data, peptide identification, and protein identification levels. Different mass spectrometers output their raw spectral data in a variety of proprietary formats, and alternative methods that assign peptides to MS/MS spectra and infer protein identifications from those peptide assignments each write their results in different formats. Here we describe an MS/MS analysis platform, the Trans-Proteomic Pipeline, which makes use of open XML file formats for storage of data at the raw spectral data, peptide, and protein levels. This platform enables uniform analysis and exchange of MS/MS data generated from a variety of different instruments, and assigned peptides using a variety of different database search programs. We demonstrate this by applying the pipeline to data sets generated by ThermoFinnigan LCQ, ABI 4700 MALDI-TOF/TOF, and Waters Q-TOF instruments, and searched in turn using SEQUEST, Mascot, and COMET.},
	URL = {https://europepmc.org/articles/PMC1681455},
}
@article {PMID24226387,
	Title = {An approach to correlate tandem mass spectral data of peptides with amino acid sequences in a protein database},
	Author = {Eng, JK and McCormack, AL and Yates, JR},
	DOI = {10.1016/1044-0305(94)80016-2},
	Number = {11},
	Volume = {5},
	Month = {November},
	Year = {1994},
	Journal = {Journal of the American Society for Mass Spectrometry},
	ISSN = {1044-0305},
	Pages = {976—989},
	Abstract = {A method to correlate the uninterpreted tandem mass spectra of peptides produced under low energy (10-50 eV) collision conditions with amino acid sequences in the Genpept database has been developed. In this method the protein database is searched to identify linear amino acid sequences within a mass tolerance of ±1 u of the precursor ion molecular weight A cross-correlation function is then used to provide a measurement of similarity between the mass-to-charge ratios for the fragment ions predicted from amino acid sequences obtained from the database and the fragment ions observed in the tandem mass spectrum. In general, a difference greater than 0.1 between the normalized cross-correlation functions of the first- and second-ranked search results indicates a successful match between sequence and spectrum. Searches of species-specific protein databases with tandem mass spectra acquired from peptides obtained from the enzymatically digested total proteins of E. coli and S. cerevisiae cells allowed matching of the spectra to amino acid sequences within proteins of these organisms. The approach described in this manuscript provides a convenient method to interpret tandem mass spectra with known sequences in a protein database.},
	URL = {http://www.cis.hut.fi/Opinnot/T-61.6070/slides2008/sequence.pdf},
}
@article {PMID14558131,
	Title = {A method for reducing the time required to match protein sequences with tandem mass spectra},
	Author = {Craig, Robertson and Beavis, Ronald C},
	DOI = {10.1002/rcm.1198},
	Number = {20},
	Volume = {17},
	Year = {2003},
	Journal = {Rapid communications in mass spectrometry : RCM},
	ISSN = {0951-4198},
	Pages = {2310—2316},
	Abstract = {An algorithm for reducing the time necessary to match a large set of peptide tandem mass spectra with a list of protein sequences is described. This algorithm breaks the process into multiple steps. A rapid survey step identifies all protein sequences that are reasonable candidates for a match with a set of tandem mass spectra. These candidates are then used as models, which are refined by detailed analysis of the set of tandem mass spectra for evidence of incomplete enzymatic hydrolysis, non-specific hydrolysis and chemical modifications of amino acid residues resulting from either post-translational modifications or sample handling. Compared with current one-step methods for matching proteins to mass spectra, this multiple-step method can decrease the time required for the calculation by several orders of magnitude.},
	URL = {https://doi.org/10.1002/rcm.1198},
}
@article {PMID10612281,
	Title = {Probability-based protein identification by searching sequence databases using mass spectrometry data},
	Author = {Perkins, DN and Pappin, DJ and Creasy, DM and Cottrell, JS},
	DOI = {10.1002/(sici)1522-2683(19991201)20:18&lt;3551::aid-elps3551&gt;3.0.co;2-2},
	Number = {18},
	Volume = {20},
	Month = {December},
	Year = {1999},
	Journal = {Electrophoresis},
	ISSN = {0173-0835},
	Pages = {3551—3567},
	Abstract = {Several algorithms have been described in the literature for protein identification by searching a sequence database using mass spectrometry data. In some approaches, the experimental data are peptide molecular weights from the digestion of a protein by an enzyme. Other approaches use tandem mass spectrometry (MS/MS) data from one or more peptides. Still others combine mass data with amino acid sequence data. We present results from a new computer program, Mascot, which integrates all three types of search. The scoring algorithm is probability based, which has a number of advantages: (i) A simple rule can be used to judge whether a result is significant or not. This is particularly useful in guarding against false positives. (ii) Scores can be compared with those from other types of search, such as sequence homology. (iii) Search parameters can be readily optimised by iteration. The strengths and limitations of probability-based scoring are discussed, particularly in the context of high throughput, fully automated protein identification.},
	URL = {https://doi.org/10.1002/(SICI)1522-2683(19991201)20:18&lt;3551::AID-ELPS3551&gt;3.0.CO;2-2},
}
