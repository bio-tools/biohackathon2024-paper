@misc{istrate2022largedatasetsoftwarementions,
      title={A large dataset of software mentions in the biomedical literature}, 
      author={Ana-Maria Istrate and Donghui Li and Dario Taraborelli and Michaela Torkar and Boris Veytsman and Ivana Williams},
      year={2022},
      eprint={2209.00693},
      archivePrefix={arXiv},
      primaryClass={cs.DL},
      url={https://arxiv.org/abs/2209.00693}, 
}
@article {PMID35111920,
	Title = {The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central},
	Author = {Schindler, David and Bensmann, Felix and Dietze, Stefan and Krüger, Frank},
	DOI = {10.7717/peerj-cs.835},
	Volume = {8},
	Year = {2022},
	Journal = {PeerJ. Computer science},
	ISSN = {2167-9843},
	Pages = {e835},
	Abstract = {Science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysing data. Thus, transparency about software used as part of the scientific process is crucial to understand provenance of individual research data and insights, is a prerequisite for reproducibility and can enable macro-analysis of the evolution of scientific methods over time. However, missing rigor in software citation practices renders the automated detection and disambiguation of software mentions a challenging problem. In this work, we provide a large-scale analysis of software usage and citation practices facilitated through an unprecedented knowledge graph of software mentions and affiliated metadata generated through supervised information extraction models trained on a unique gold standard &lt;i&gt;corpus&lt;/i&gt; and applied to more than 3 million scientific articles. Our information extraction approach distinguishes different types of software and mentions, disambiguates mentions and outperforms the state-of-the-art significantly, leading to the most comprehensive &lt;i&gt;corpus&lt;/i&gt; of 11.8 M software mentions that are described through a knowledge graph consisting of more than 300 M triples. Our analysis provides insights into the evolution of software usage and citation patterns across various fields, ranks of journals, and impact of publications. Whereas, to the best of our knowledge, this is the most comprehensive analysis of software use and citation at the time, all data and models are shared publicly to facilitate further research into scientific use and citation of software.},
	URL = {https://europepmc.org/articles/PMC8771769},
}
@inproceedings{10.1145/3459637.3481936,
	author = {Lopez, Patrice and Du, Caifan and Cohoon, Johanna and Ram, Karthik and Howison, James},
	title = {Mining Software Entities in Scientific Literature: Document-level NER for an Extremely Imbalance and Large-scale Task},
	year = {2021},
	isbn = {9781450384469},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3459637.3481936},
	doi = {10.1145/3459637.3481936},
	abstract = {We present a comprehensive information extraction system dedicated to software entities in scientific literature. This task combines the complexity of automatic reading of scientific documents (PDF processing, document structuring, styled/rich text, scaling) with challenges specific to mining software entities: high heterogeneity and extreme sparsity of mentions, document-level cross-references, disambiguation of noisy software mentions and poor portability of Machine Learning approaches between highly specialized domains. While NER is a key component to recognize new and unseen software, considering this task as a simple NER application fails to address most of these issues.In this paper, we propose a multi-model Machine Learning approach where raw documents are ingested by a cascade of document structuring processes applied not to text, but to layout token elements. The cascading process further enriches the relevant structures of the document with a Deep Learning software mention recognizer adapted to the high sparsity of mentions. The Machine Learning cascade culminates with entity disambiguation to alleviate false positives and to provide software entity linking. A bibliographical reference resolution is integrated to the process for attaching references cited alongside the software mentions.Based on the first gold-standard annotated dataset developed for software mentions, this work establishes a new reference end-to-end performance for this task. Experiments with the CORD-19 publications have further demonstrated that our system provides practically usable performance and is scalable to the whole scientific corpus, enabling novel applications for crediting research software and for better understanding the impact of software in science.},
	booktitle = {Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
	pages = {3986–3995},
	numpages = {10},
	keywords = {software, scientific literature, entity recognition, entity disambiguation, document analysis},
	location = {Virtual Event, Queensland, Australia},
	series = {CIKM '21}
}
@misc{druskat2024dontmentionitapproach,
      title={Don't mention it: An approach to assess challenges to using software mentions for citation and discoverability research},
      author={Stephan Druskat and Neil P. Chue Hong and Sammie Buzzard and Olexandr Konovalov and Patrick Kornek},
      year={2024},
      eprint={2402.14602},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2402.14602},
}
@article {PMID23148064,
	Title = {Comet: an open-source MS/MS sequence database search tool},
	Author = {Eng, Jimmy K and Jahan, Tahmina A and Hoopmann, Michael R},
	DOI = {10.1002/pmic.201200439},
	Number = {1},
	Volume = {13},
	Month = {January},
	Year = {2013},
	Journal = {Proteomics},
	ISSN = {1615-9853},
	Pages = {22—24},
	Abstract = {Proteomics research routinely involves identifying peptides and proteins via MS/MS sequence database search. Thus the database search engine is an integral tool in many proteomics research groups. Here, we introduce the Comet search engine to the existing landscape of commercial and open-source database search tools. Comet is open source, freely available, and based on one of the original sequence database search tools that has been widely used for many years.},
	URL = {https://doi.org/10.1002/pmic.201200439},
}
@article {PMID21622656,
	Title = {CoMet--a web server for comparative functional profiling of metagenomes},
	Author = {Lingner, Thomas and Asshauer, Kathrin Petra and Schreiber, Fabian and Meinicke, Peter},
	DOI = {10.1093/nar/gkr388},
	Number = {Web Server issue},
	Volume = {39},
	Month = {July},
	Year = {2011},
	Journal = {Nucleic acids research},
	ISSN = {0305-1048},
	Pages = {W518—23},
	Abstract = {Analyzing the functional potential of newly sequenced genomes and metagenomes has become a common task in biomedical and biological research. With the advent of high-throughput sequencing technologies comparative metagenomics opens the way to elucidate the genetically determined similarities and differences of complex microbial communities. We developed the web server 'CoMet' (http://comet.gobics.de), which provides an easy-to-use comparative metagenomics platform that is well-suitable for the analysis of large collections of metagenomic short read data. CoMet combines the ORF finding and subsequent assignment of protein sequences to Pfam domain families with a comparative statistical analysis. Besides comprehensive tabular data files, the CoMet server also provides visually interpretable output in terms of hierarchical clustering and multi-dimensional scaling plots and thus allows a quick overview of a given set of metagenomic samples.},
	URL = {https://europepmc.org/articles/PMC3125781},
}
@article {PMID32034124,
	Title = {The COMET toolkit for composing customizable genetic programs in mammalian cells},
	Author = {Donahue, Patrick S and Draut, Joseph W and Muldoon, Joseph J and Edelstein, Hailey I and Bagheri, Neda and Leonard, Joshua N},
	DOI = {10.1038/s41467-019-14147-5},
	Number = {1},
	Volume = {11},
	Month = {February},
	Year = {2020},
	Journal = {Nature communications},
	ISSN = {2041-1723},
	Pages = {779},
	Abstract = {Engineering mammalian cells to carry out sophisticated and customizable genetic programs requires a toolkit of multiple orthogonal and well-characterized transcription factors (TFs). To address this need, we develop the COmposable Mammalian Elements of Transcription (COMET)-an ensemble of TFs and promoters that enable the design and tuning of gene expression to an extent not, to the best of our knowledge, previously possible. COMET currently comprises 44 activating and 12 inhibitory zinc-finger TFs and 83 cognate promoters, combined in a framework that readily accommodates new parts. This system can tune gene expression over three orders of magnitude, provides chemically inducible control of TF activity, and enables single-layer Boolean logic. We also develop a mathematical model that provides mechanistic insights into COMET performance characteristics. Altogether, COMET enables the design and construction of customizable genetic programs in mammalian cells.},
	URL = {https://europepmc.org/articles/PMC7005830},
}
@article {PMID25928765,
	Title = {coMET: visualisation of regional epigenome-wide association scan results and DNA co-methylation patterns},
	Author = {Martin, Tiphaine C and Yet, Idil and Tsai, Pei-Chien and Bell, Jordana T},
	DOI = {10.1186/s12859-015-0568-2},
	Volume = {16},
	Month = {April},
	Year = {2015},
	Journal = {BMC bioinformatics},
	ISSN = {1471-2105},
	Pages = {131},
	Abstract = {&lt;h4&gt;Background&lt;/h4&gt;Epigenome-wide association scans (EWAS) are an increasingly powerful and widely-used approach to assess the role of epigenetic variation in human complex traits. However, this rapidly emerging field lacks dedicated visualisation tools that can display features specific to epigenetic datasets.&lt;h4&gt;Result&lt;/h4&gt;We developed coMET, an R package and online tool for visualisation of EWAS results in a genomic region of interest. coMET generates a regional plot of epigenetic-phenotype association results and the estimated DNA methylation correlation between CpG sites (co-methylation), with further options to visualise genomic annotations based on ENCODE data, gene tracks, reference CpG-sites, and user-defined features. The tool can be used to display phenotype association signals and correlation patterns of microarray or sequencing-based DNA methylation data, such as Illumina Infinium 450k, WGBS, or MeDIP-seq, as well as other types of genomic data, such as gene expression profiles. The software is available as a user-friendly online tool from http://epigen.kcl.ac.uk/comet and as an R Bioconductor package. Source code, examples, and full documentation are also available from GitHub.&lt;h4&gt;Conclusion&lt;/h4&gt;Our new software allows visualisation of EWAS results with functional genomic annotations and with estimation of co-methylation patterns. coMET is available to a wide audience as an online tool and R package, and can be a valuable resource to interpret results in the fast growing field of epigenetics. The software is designed for epigenetic data, but can also be applied to genomic and functional genomic datasets in any species.},
	URL = {https://europepmc.org/articles/PMC4422463},
}
@article {PMID31405382,
	Title = {The bio.tools registry of software tools and data resources for the life sciences},
	Author = {Ison, Jon and Ienasescu, Hans and Chmura, Piotr and Rydza, Emil and Ménager, Hervé and Kalaš, Matúš and Schwämmle, Veit and Grüning, Björn and Beard, Niall and Lopez, Rodrigo and Duvaud, Severine and Stockinger, Heinz and Persson, Bengt and Vařeková, Radka Svobodová and Raček, Tomáš and Vondrášek, Jiří and Peterson, Hedi and Salumets, Ahto and Jonassen, Inge and Hooft, Rob and Nyrönen, Tommi and Valencia, Alfonso and Capella, Salvador and Gelpí, Josep and Zambelli, Federico and Savakis, Babis and Leskošek, Brane and Rapacki, Kristoffer and Blanchet, Christophe and Jimenez, Rafael and Oliveira, Arlindo and Vriend, Gert and Collin, Olivier and van Helden, Jacques and Løngreen, Peter and Brunak, Søren},
	DOI = {10.1186/s13059-019-1772-6},
	Number = {1},
	Volume = {20},
	Month = {August},
	Year = {2019},
	Journal = {Genome biology},
	ISSN = {1474-7596},
	Pages = {164},
	Abstract = {Bioinformaticians and biologists rely increasingly upon workflows for the flexible utilization of the many life science tools that are needed to optimally convert data into knowledge. We outline a pan-European enterprise to provide a catalogue ( https://bio.tools ) of tools and databases that can be used in these workflows. bio.tools not only lists where to find resources, but also provides a wide variety of practical information.},
	URL = {https://europepmc.org/articles/PMC6691543},
}
@article {PMID23479348,
	Title = {EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats},
	Author = {Ison, Jon and Kalas, Matús and Jonassen, Inge and Bolser, Dan and Uludag, Mahmut and McWilliam, Hamish and Malone, James and Lopez, Rodrigo and Pettifer, Steve and Rice, Peter},
	DOI = {10.1093/bioinformatics/btt113},
	Number = {10},
	Volume = {29},
	Month = {May},
	Year = {2013},
	Journal = {Bioinformatics (Oxford, England)},
	ISSN = {1367-4803},
	Pages = {1325—1332},
	Abstract = {&lt;h4&gt;Motivation&lt;/h4&gt;Advancing the search, publication and integration of bioinformatics tools and resources demands consistent machine-understandable descriptions. A comprehensive ontology allowing such descriptions is therefore required.&lt;h4&gt;Results&lt;/h4&gt;EDAM is an ontology of bioinformatics operations (tool or workflow functions), types of data and identifiers, application domains and data formats. EDAM supports semantic annotation of diverse entities such as Web services, databases, programmatic libraries, standalone tools, interactive applications, data schemas, datasets and publications within bioinformatics. EDAM applies to organizing and finding suitable tools and data and to automating their integration into complex applications or workflows. It includes over 2200 defined concepts and has successfully been used for annotations and implementations.&lt;h4&gt;Availability&lt;/h4&gt;The latest stable version of EDAM is available in OWL format from http://edamontology.org/EDAM.owl and in OBO format from http://edamontology.org/EDAM.obo. It can be viewed online at the NCBO BioPortal and the EBI Ontology Lookup Service. For documentation and license please refer to http://edamontology.org. This article describes version 1.2 available at http://edamontology.org/EDAM_1.2.owl.&lt;h4&gt;Contact&lt;/h4&gt;jison@ebi.ac.uk.},
	URL = {https://europepmc.org/articles/PMC3654706},
}
@article {PMID39496564,
	Title = {Optimization of protein identifications through the use of different chromatographic approaches and bioinformatic pipelines},
	Author = {Castaño, Jesus D and Beaudry, Francis},
	DOI = {10.1002/rcm.9937},
	Number = {1},
	Volume = {39},
	Month = {January},
	Year = {2025},
	Journal = {Rapid communications in mass spectrometry : RCM},
	ISSN = {0951-4198},
	Pages = {e9937},
	Abstract = {&lt;h4&gt;Rationale&lt;/h4&gt;Selection of proteomic workflows for a given project can be a daunting task. This research provides a guide outlining the impact on protein identification of different steps such as chromatographic separation, data acquisition strategies, and bioinformatic pipelines. The data presented here will help experts and nonexpert proteomic users to increase proteome coverage and peptide identification.&lt;h4&gt;Methods&lt;/h4&gt;HeLa protein digests were analyzed through different C18 chromatographic columns (15 and 50 cm in length), using top 12 data-dependent acquisition (DDA), top 20 DDA, and data-independent acquisition (DIA) with a nanospray source in positive mode in a Thermo Q Exactive instrument. The raw data were analyzed using different search engines, rescoring approaches, and multi-engine searches. The results were analyzed in the context of peptide and protein identifications, precursor properties, and computation requirements to understand the differences between methods.&lt;h4&gt;Results&lt;/h4&gt;Our results showed that higher column lengths and top N DDA approaches were able to significantly increase protein identifications. The use of multiple search engines yielded limited gains, whereas the use of rescoring methods clearly outperformed other strategies. Finally, DIA approaches, although successful at generating new identifications, had a limited performance influenced by the previous collection of DDA data, which could prohibitively increase instrument time. Nonetheless, the use of library-free methods showed promising results.&lt;h4&gt;Conclusions&lt;/h4&gt;Our results highlight the impact of different experimental approaches on proteome coverage. Changes in chromatographic columns, data acquisition, or bioinformatic analysis can significantly increase the number of protein identifications (&gt;400%). Thus, this research provides a reference upon which to build a successful proteomic workflow with different considerations at every step.},
	URL = {https://doi.org/10.1002/rcm.9937},
}
@article {PMID16729052,
	Title = {A uniform proteomics MS/MS analysis platform utilizing open XML file formats},
	Author = {Keller, Andrew and Eng, Jimmy and Zhang, Ning and Li, Xiao-jun and Aebersold, Ruedi},
	DOI = {10.1038/msb4100024},
	Volume = {1},
	Year = {2005},
	Journal = {Molecular systems biology},
	ISSN = {1744-4292},
	Pages = {2005.0017},
	Abstract = {The analysis of tandem mass (MS/MS) data to identify and quantify proteins is hampered by the heterogeneity of file formats at the raw spectral data, peptide identification, and protein identification levels. Different mass spectrometers output their raw spectral data in a variety of proprietary formats, and alternative methods that assign peptides to MS/MS spectra and infer protein identifications from those peptide assignments each write their results in different formats. Here we describe an MS/MS analysis platform, the Trans-Proteomic Pipeline, which makes use of open XML file formats for storage of data at the raw spectral data, peptide, and protein levels. This platform enables uniform analysis and exchange of MS/MS data generated from a variety of different instruments, and assigned peptides using a variety of different database search programs. We demonstrate this by applying the pipeline to data sets generated by ThermoFinnigan LCQ, ABI 4700 MALDI-TOF/TOF, and Waters Q-TOF instruments, and searched in turn using SEQUEST, Mascot, and COMET.},
	URL = {https://europepmc.org/articles/PMC1681455},
}
@article {PMID24226387,
	Title = {An approach to correlate tandem mass spectral data of peptides with amino acid sequences in a protein database},
	Author = {Eng, JK and McCormack, AL and Yates, JR},
	DOI = {10.1016/1044-0305(94)80016-2},
	Number = {11},
	Volume = {5},
	Month = {November},
	Year = {1994},
	Journal = {Journal of the American Society for Mass Spectrometry},
	ISSN = {1044-0305},
	Pages = {976—989},
	Abstract = {A method to correlate the uninterpreted tandem mass spectra of peptides produced under low energy (10-50 eV) collision conditions with amino acid sequences in the Genpept database has been developed. In this method the protein database is searched to identify linear amino acid sequences within a mass tolerance of ±1 u of the precursor ion molecular weight A cross-correlation function is then used to provide a measurement of similarity between the mass-to-charge ratios for the fragment ions predicted from amino acid sequences obtained from the database and the fragment ions observed in the tandem mass spectrum. In general, a difference greater than 0.1 between the normalized cross-correlation functions of the first- and second-ranked search results indicates a successful match between sequence and spectrum. Searches of species-specific protein databases with tandem mass spectra acquired from peptides obtained from the enzymatically digested total proteins of E. coli and S. cerevisiae cells allowed matching of the spectra to amino acid sequences within proteins of these organisms. The approach described in this manuscript provides a convenient method to interpret tandem mass spectra with known sequences in a protein database.},
	URL = {http://www.cis.hut.fi/Opinnot/T-61.6070/slides2008/sequence.pdf},
}
@article {PMID14558131,
	Title = {A method for reducing the time required to match protein sequences with tandem mass spectra},
	Author = {Craig, Robertson and Beavis, Ronald C},
	DOI = {10.1002/rcm.1198},
	Number = {20},
	Volume = {17},
	Year = {2003},
	Journal = {Rapid communications in mass spectrometry : RCM},
	ISSN = {0951-4198},
	Pages = {2310—2316},
	Abstract = {An algorithm for reducing the time necessary to match a large set of peptide tandem mass spectra with a list of protein sequences is described. This algorithm breaks the process into multiple steps. A rapid survey step identifies all protein sequences that are reasonable candidates for a match with a set of tandem mass spectra. These candidates are then used as models, which are refined by detailed analysis of the set of tandem mass spectra for evidence of incomplete enzymatic hydrolysis, non-specific hydrolysis and chemical modifications of amino acid residues resulting from either post-translational modifications or sample handling. Compared with current one-step methods for matching proteins to mass spectra, this multiple-step method can decrease the time required for the calculation by several orders of magnitude.},
	URL = {https://doi.org/10.1002/rcm.1198},
}
@article {PMID10612281,
	Title = {Probability-based protein identification by searching sequence databases using mass spectrometry data},
	Author = {Perkins, DN and Pappin, DJ and Creasy, DM and Cottrell, JS},
	DOI = {10.1002/(sici)1522-2683(19991201)20:18&lt;3551::aid-elps3551&gt;3.0.co;2-2},
	Number = {18},
	Volume = {20},
	Month = {December},
	Year = {1999},
	Journal = {Electrophoresis},
	ISSN = {0173-0835},
	Pages = {3551—3567},
	Abstract = {Several algorithms have been described in the literature for protein identification by searching a sequence database using mass spectrometry data. In some approaches, the experimental data are peptide molecular weights from the digestion of a protein by an enzyme. Other approaches use tandem mass spectrometry (MS/MS) data from one or more peptides. Still others combine mass data with amino acid sequence data. We present results from a new computer program, Mascot, which integrates all three types of search. The scoring algorithm is probability based, which has a number of advantages: (i) A simple rule can be used to judge whether a result is significant or not. This is particularly useful in guarding against false positives. (ii) Scores can be compared with those from other types of search, such as sequence homology. (iii) Search parameters can be readily optimised by iteration. The strengths and limitations of probability-based scoring are discussed, particularly in the context of high throughput, fully automated protein identification.},
	URL = {https://doi.org/10.1002/(SICI)1522-2683(19991201)20:18&lt;3551::AID-ELPS3551&gt;3.0.CO;2-2},
}
@article {PMID19029910,
	Title = {MaxQuant enables high peptide identification rates, individualized p.p.b.-range mass accuracies and proteome-wide protein quantification},
	Author = {Cox, Jürgen and Mann, Matthias},
	DOI = {10.1038/nbt.1511},
	Number = {12},
	Volume = {26},
	Month = {December},
	Year = {2008},
	Journal = {Nature biotechnology},
	ISSN = {1087-0156},
	Pages = {1367—1372},
	Abstract = {Efficient analysis of very large amounts of raw data for peptide identification and protein quantification is a principal challenge in mass spectrometry (MS)-based proteomics. Here we describe MaxQuant, an integrated suite of algorithms specifically developed for high-resolution, quantitative MS data. Using correlation analysis and graph theory, MaxQuant detects peaks, isotope clusters and stable amino acid isotope-labeled (SILAC) peptide pairs as three-dimensional objects in m/z, elution time and signal intensity space. By integrating multiple mass measurements and correcting for linear and nonlinear mass offsets, we achieve mass accuracy in the p.p.b. range, a sixfold increase over standard techniques. We increase the proportion of identified fragmentation spectra to 73% for SILAC peptide pairs via unambiguous assignment of isotope and missed-cleavage state and individual mass precision. MaxQuant automatically quantifies several hundred thousand peptides per SILAC-proteome experiment and allows statistically robust identification and quantification of &gt;4,000 proteins in mammalian cell lysates.},
	URL = {https://doi.org/10.1038/nbt.1511},
}
@article {PMID27122644,
	Title = {Scientific workflows for bibliometrics},
	Author = {Guler, Arzu Tugce and Waaijer, Cathelijn J F and Palmblad, Magnus},
	DOI = {10.1007/s11192-016-1885-6},
	Volume = {107},
	Year = {2016},
	Journal = {Scientometrics},
	ISSN = {0138-9130},
	Pages = {385—398},
	Abstract = {Scientific workflows organize the assembly of specialized software into an overall data flow and are particularly well suited for multi-step analyses using different types of software tools. They are also favorable in terms of reusability, as previously designed workflows could be made publicly available through the myExperiment community and then used in other workflows. We here illustrate how scientific workflows and the Taverna workbench in particular can be used in bibliometrics. We discuss the specific capabilities of Taverna that makes this software a powerful tool in this field, such as automated data import via Web services, data extraction from XML by XPaths, and statistical analysis and visualization with R. The support of the latter is particularly relevant, as it allows integration of a number of recently developed R packages specifically for bibliometrics. Examples are used to illustrate the possibilities of Taverna in the fields of bibliometrics and scientometrics.},
	URL = {https://europepmc.org/articles/PMC4833826},
}
@article {PMID30702898,
	Title = {Progress and Challenges in Ocean Metaproteomics and Proposed Best Practices for Data Sharing},
	Author = {Saito, Mak A and Bertrand, Erin M and Duffy, Megan E and Gaylord, David A and Held, Noelle A and Hervey, William Judson and Hettich, Robert L and Jagtap, Pratik D and Janech, Michael G and Kinkade, Danie B and Leary, Dagmar H and McIlvin, Matthew R and Moore, Eli K and Morris, Robert M and Neely, Benjamin A and Nunn, Brook L and Saunders, Jaclyn K and Shepherd, Adam I and Symmonds, Nicholas I and Walsh, David A},
	DOI = {10.1021/acs.jproteome.8b00761},
	Number = {4},
	Volume = {18},
	Month = {April},
	Year = {2019},
	Journal = {Journal of proteome research},
	ISSN = {1535-3893},
	Pages = {1461—1476},
	Abstract = {Ocean metaproteomics is an emerging field enabling discoveries about marine microbial communities and their impact on global biogeochemical processes. Recent ocean metaproteomic studies have provided insight into microbial nutrient transport, colimitation of carbon fixation, the metabolism of microbial biofilms, and dynamics of carbon flux in marine ecosystems. Future methodological developments could provide new capabilities such as characterizing long-term ecosystem changes, biogeochemical reaction rates, and in situ stoichiometries. Yet challenges remain for ocean metaproteomics due to the great biological diversity that produces highly complex mass spectra, as well as the difficulty in obtaining and working with environmental samples. This review summarizes the progress and challenges facing ocean metaproteomic scientists and proposes best practices for data sharing of ocean metaproteomic data sets, including the data types and metadata needed to enable intercomparisons of protein distributions and annotations that could foster global ocean metaproteomic capabilities.},
	URL = {https://europepmc.org/articles/PMC7575043},
}
@article {PMID22253597,
	Title = {The bZIP transcription factor Rca1p is a central regulator of a novel CO2 sensing pathway in yeast},
	Author = {Cottier, Fabien and Raymond, Martine and Kurzai, Oliver and Bolstad, Marianne and Leewattanapasuk, Worraanong and Jiménez-López, Claudia and Lorenz, Michael C and Sanglard, Dominique and Váchová, Libuše and Pavelka, Norman and Palková, Zdena and Mühlschlegel, Fritz A},
	DOI = {10.1371/journal.ppat.1002485},
	Number = {1},
	Volume = {8},
	Month = {January},
	Year = {2012},
	Journal = {PLoS pathogens},
	ISSN = {1553-7366},
	Pages = {e1002485},
	Abstract = {Like many organisms the fungal pathogen Candida albicans senses changes in the environmental CO(2) concentration. This response involves two major proteins: adenylyl cyclase and carbonic anhydrase (CA). Here, we demonstrate that CA expression is tightly controlled by the availability of CO(2) and identify the bZIP transcription factor Rca1p as the first CO(2) regulator of CA expression in yeast. We show that Rca1p upregulates CA expression during contact with mammalian phagocytes and demonstrate that serine 124 is critical for Rca1p signaling, which occurs independently of adenylyl cyclase. ChIP-chip analysis and the identification of Rca1p orthologs in the model yeast Saccharomyces cerevisiae (Cst6p) point to the broad significance of this novel pathway in fungi. By using advanced microscopy we visualize for the first time the impact of CO(2) build-up on gene expression in entire fungal populations with an exceptional level of detail. Our results present the bZIP protein Rca1p as the first fungal regulator of carbonic anhydrase, and reveal the existence of an adenylyl cyclase independent CO(2) sensing pathway in yeast. Rca1p appears to regulate cellular metabolism in response to CO(2) availability in environments as diverse as the phagosome, yeast communities or liquid culture.},
	URL = {https://europepmc.org/articles/PMC3257301},
}
@article{PMID338821209,
    author = {Hatos, András and Quaglia, Federica and Piovesan, Damiano and Tosatto, Silvio C E},
    title = {APICURON: a database to credit and acknowledge the work of biocurators},
    journal = {Database},
    volume = {2021},
    pages = {baab019},
    year = {2021},
    month = {04},
    doi = {10.1093/database/baab019},
    url = {https://doi.org/10.1093/database/baab019},
    eprint = {https://academic.oup.com/database/article-pdf/doi/10.1093/database/baab019/37243737/baab019.pdf},
}
@article{PMID23768135,
  title = {{{bioNerDS}}: Exploring Bioinformatics' Database and Software Use through Literature Mining},
  author = {Duck, Geraint and Nenadic, Goran and Brass, Andy and Robertson, David L. and Stevens, Robert},
  year = {2013},
  month = jun,
  journal = {BMC Bioinformatics},
  volume = {14},
  number = {1},
  pages = {194},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-194},
  abstract = {Biology-focused databases and software define bioinformatics and their use is central to computational biology. In such a complex and dynamic field, it is of interest to understand what resources are available, which are used, how much they are used, and for what they are used. While scholarly literature surveys can provide some insights, large-scale computer-based approaches to identify mentions of bioinformatics databases and software from primary literature would automate systematic cataloguing, facilitate the monitoring of usage, and provide the foundations for the recovery of computational methods for analysing biological data, with the long-term aim of identifying best/common practice in different areas of biology.}
}

@misc{OpenAIRE,
	author = {Katerina Iatropoulou},
	title = {{O}pen{A}{I}{R}{E} --- openaire.eu},
	howpublished = {\url{https://www.openaire.eu/}},
	year = {},
	note = {[Accessed 21-03-2025]},
}

@inproceedings{Bodapati,
    title = "Robustness to Capitalization Errors in Named Entity Recognition",
    author = "Bodapati, Sravan  and
      Yun, Hyokun  and
      Al-Onaizan, Yaser",
    editor = "Xu, Wei  and
      Ritter, Alan  and
      Baldwin, Tim  and
      Rahimi, Afshin",
    booktitle = "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5531/",
    doi = "10.18653/v1/D19-5531",
    pages = "237--242",
    abstract = "Robustness to capitalization errors is a highly desirable characteristic of named entity recognizers, yet we find standard models for the task are surprisingly brittle to such noise. Existing methods to improve robustness to the noise completely discard given orthographic information, which significantly degrades their performance on well-formed text. We propose a simple alternative approach based on data augmentation, which allows the model to learn to utilize or ignore orthographic information depending on its usefulness in the context. It achieves competitive robustness to capitalization errors while making negligible compromise to its performance on well-formed text and significantly improving generalization power on noisy user-generated text. Our experiments clearly and consistently validate our claim across different types of machine learning models, languages, and dataset sizes."
}
